{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14010596,"sourceType":"datasetVersion","datasetId":8925232}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport lightgbm as lgb\nfrom scipy.optimize import curve_fit\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom joblib import Parallel, delayed\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:28:33.440461Z","iopub.execute_input":"2025-12-20T18:28:33.441231Z","iopub.status.idle":"2025-12-20T18:28:33.447963Z","shell.execute_reply.started":"2025-12-20T18:28:33.441201Z","shell.execute_reply":"2025-12-20T18:28:33.447260Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:32:22.860003Z","iopub.execute_input":"2025-12-20T18:32:22.860724Z","iopub.status.idle":"2025-12-20T18:32:22.864091Z","shell.execute_reply.started":"2025-12-20T18:32:22.860696Z","shell.execute_reply":"2025-12-20T18:32:22.863382Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/mallorn-dataset' \nprint(f\"Data Path: {DATA_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:29:44.070934Z","iopub.execute_input":"2025-12-20T18:29:44.071471Z","iopub.status.idle":"2025-12-20T18:29:44.075258Z","shell.execute_reply.started":"2025-12-20T18:29:44.071444Z","shell.execute_reply":"2025-12-20T18:29:44.074615Z"}},"outputs":[{"name":"stdout","text":"Data Path: /kaggle/input/mallorn-dataset\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"def bazin_func(t, A, B, t0, tau_fall, tau_rise):\n    with np.errstate(over='ignore', invalid='ignore'):\n        flux = A * (np.exp(-(t - t0) / tau_fall) / (1 + np.exp(-(t - t0) / tau_rise))) + B\n    return np.nan_to_num(flux)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:29:55.635276Z","iopub.execute_input":"2025-12-20T18:29:55.635864Z","iopub.status.idle":"2025-12-20T18:29:55.640081Z","shell.execute_reply.started":"2025-12-20T18:29:55.635838Z","shell.execute_reply":"2025-12-20T18:29:55.639335Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"def fit_bazin(time, flux, flux_err):\n    if len(time) < 5: \n        return {k: np.nan for k in ['A', 'B', 't0', 'tau_fall', 'tau_rise', 'chi2']}\n\n    peak_idx = np.argmax(flux)\n    # Initial guesses\n    p0 = [flux[peak_idx], np.min(flux), time[peak_idx], 50.0, 10.0]\n    # Bounds\n    bounds = ([0, -np.inf, time.min()-50, 1e-3, 1e-3], [np.inf, np.inf, time.max()+50, 500, 500])\n\n    try:\n        popt, _ = curve_fit(bazin_func, time, flux, p0=p0, sigma=flux_err, bounds=bounds, maxfev=1000)\n        residuals = flux - bazin_func(time, *popt)\n        chi2 = np.sum((residuals / flux_err)**2) / (len(time) - 5)\n        return {'A': popt[0], 'B': popt[1], 't0': popt[2], 'tau_fall': popt[3], 'tau_rise': popt[4], 'chi2': chi2}\n    except:\n        return {k: np.nan for k in ['A', 'B', 't0', 'tau_fall', 'tau_rise', 'chi2']}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:30:10.703472Z","iopub.execute_input":"2025-12-20T18:30:10.703885Z","iopub.status.idle":"2025-12-20T18:30:10.710391Z","shell.execute_reply.started":"2025-12-20T18:30:10.703854Z","shell.execute_reply":"2025-12-20T18:30:10.709867Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def get_gp_prediction(time, flux, flux_err, t_query):\n    if len(time) < 3: return np.nan\n    kernel = C(1.0) * RBF(length_scale=20.0) + WhiteKernel(noise_level=1.0)\n    gp = GaussianProcessRegressor(kernel=kernel, alpha=flux_err**2, n_restarts_optimizer=0)\n    try:\n        gp.fit(time.reshape(-1, 1), flux)\n        pred, _ = gp.predict(np.array([[t_query]]), return_std=True)\n        return pred[0]\n    except:\n        return np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:30:22.343791Z","iopub.execute_input":"2025-12-20T18:30:22.344388Z","iopub.status.idle":"2025-12-20T18:30:22.349099Z","shell.execute_reply.started":"2025-12-20T18:30:22.344360Z","shell.execute_reply":"2025-12-20T18:30:22.348466Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def process_single_object(obj_id, df_obj):\n    feats = {'object_id': obj_id}\n    \n    t_min = df_obj['Time (MJD)'].min()\n    df_obj['Time_Rel'] = df_obj['Time (MJD)'] - t_min\n    \n    filters = ['u', 'g', 'r', 'i', 'z', 'y']\n    \n    peak_time = np.nan\n    max_flux_global = -np.inf\n    \n    for f in filters:\n        df_f = df_obj[df_obj['Filter'] == f]\n        if df_f.empty:\n            for stat in ['mean', 'max', 'min', 'std', 'skew']:\n                feats[f'{f}_{stat}'] = np.nan\n            continue\n            \n        feats[f'{f}_mean'] = df_f['Flux'].mean()\n        feats[f'{f}_max'] = df_f['Flux'].max()\n        feats[f'{f}_min'] = df_f['Flux'].min()\n        feats[f'{f}_std'] = df_f['Flux'].std()\n        feats[f'{f}_skew'] = df_f['Flux'].skew()\n        \n        if f in ['g', 'r']:\n            current_max = df_f['Flux'].max()\n            if current_max > max_flux_global:\n                max_flux_global = current_max\n                peak_time = df_f.loc[df_f['Flux'].idxmax(), 'Time_Rel']\n\n        if f in ['g', 'r', 'i']:\n            bazin = fit_bazin(df_f['Time_Rel'].values, df_f['Flux'].values, df_f['Flux_err'].values)\n            for k, v in bazin.items():\n                feats[f'bazin_{f}_{k}'] = v\n\n    if not np.isnan(peak_time):\n        flux_at_peak = {}\n        for f in filters:\n            df_f = df_obj[df_obj['Filter'] == f]\n            flux_at_peak[f] = get_gp_prediction(\n                df_f['Time_Rel'].values, df_f['Flux'].values, df_f['Flux_err'].values, peak_time\n            )\n        \n        pairs = [('u','g'), ('g','r'), ('r','i'), ('i','z')]\n        for f1, f2 in pairs:\n            val1 = flux_at_peak.get(f1, np.nan)\n            val2 = flux_at_peak.get(f2, np.nan)\n            feats[f'gp_color_{f1}_{f2}'] = val1 - val2 if (not np.isnan(val1) and not np.isnan(val2)) else np.nan\n            \n    return feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:30:55.504680Z","iopub.execute_input":"2025-12-20T18:30:55.505307Z","iopub.status.idle":"2025-12-20T18:30:55.514560Z","shell.execute_reply.started":"2025-12-20T18:30:55.505277Z","shell.execute_reply":"2025-12-20T18:30:55.513838Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def extract_features_parallel(log_df, data_path, n_jobs=-1):\n    \"\"\"Load từng file lightcurve và trích xuất features song song\"\"\"\n    print(\"Loading raw lightcurves into memory...\")\n    all_chunks = []\n    unique_splits = log_df['split'].unique()\n    \n    for split in unique_splits:\n        is_train = 'target' in log_df.columns\n        filename = 'train_full_lightcurves.csv' if is_train else 'test_full_lightcurves.csv'\n        \n        path = os.path.join(data_path, split, filename)\n        if os.path.exists(path):\n            df_chunk = pd.read_csv(path)\n            valid_ids = set(log_df[log_df['split'] == split]['object_id'])\n            df_chunk = df_chunk[df_chunk['object_id'].isin(valid_ids)]\n            all_chunks.append(df_chunk)\n            \n    if not all_chunks:\n        print(\"Error: No lightcurves found!\")\n        return pd.DataFrame()\n\n    full_lc = pd.concat(all_chunks)\n    \n    grouped = full_lc.groupby('object_id')\n    object_ids = list(grouped.groups.keys())\n    \n    print(f\"Extracting features for {len(object_ids)} objects using {n_jobs} cores...\")\n    \n    results = Parallel(n_jobs=n_jobs, backend='loky')(\n        delayed(process_single_object)(obj_id, grouped.get_group(obj_id))\n        for obj_id in tqdm(object_ids)\n    )\n    \n    return pd.DataFrame(results)\n\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:31:22.244320Z","iopub.execute_input":"2025-12-20T18:31:22.244603Z","iopub.status.idle":"2025-12-20T18:31:22.251968Z","shell.execute_reply.started":"2025-12-20T18:31:22.244579Z","shell.execute_reply":"2025-12-20T18:31:22.251116Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"print(\"--- PROCESSING TRAIN DATA ---\")\ntrain_log = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n\ndf_train_features = extract_features_parallel(train_log, DATA_PATH, n_jobs=4)\n\ndf_train_final = train_log.merge(df_train_features, on='object_id', how='left')\nprint(f\"Train Data Shape: {df_train_final.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:35:20.130448Z","iopub.execute_input":"2025-12-20T18:35:20.131086Z","iopub.status.idle":"2025-12-20T18:40:56.282756Z","shell.execute_reply.started":"2025-12-20T18:35:20.131059Z","shell.execute_reply":"2025-12-20T18:40:56.282137Z"}},"outputs":[{"name":"stdout","text":"--- PROCESSING TRAIN DATA ---\nLoading raw lightcurves into memory...\nExtracting features for 3043 objects using 4 cores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3043 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22f65557b4db4668b2c74c33293b570d"}},"metadata":{}},{"name":"stdout","text":"Train Data Shape: (3043, 60)\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"ignore_cols = ['object_id', 'target', 'split', 'English Translation', 'SpecType']\nfeatures = [c for c in df_train_final.columns if c not in ignore_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:40:56.284101Z","iopub.execute_input":"2025-12-20T18:40:56.284333Z","iopub.status.idle":"2025-12-20T18:40:56.287883Z","shell.execute_reply.started":"2025-12-20T18:40:56.284313Z","shell.execute_reply":"2025-12-20T18:40:56.287319Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"X = df_train_final[features]\ny = df_train_final['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:40:56.305055Z","iopub.execute_input":"2025-12-20T18:40:56.305264Z","iopub.status.idle":"2025-12-20T18:40:56.318377Z","shell.execute_reply.started":"2025-12-20T18:40:56.305246Z","shell.execute_reply":"2025-12-20T18:40:56.317994Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"for col in X.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:40:56.319106Z","iopub.execute_input":"2025-12-20T18:40:56.319305Z","iopub.status.idle":"2025-12-20T18:40:56.333283Z","shell.execute_reply.started":"2025-12-20T18:40:56.319289Z","shell.execute_reply":"2025-12-20T18:40:56.332872Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"params = {\n    'objective': 'binary',\n    'metric': 'binary_logloss',\n    'boosting_type': 'gbdt',\n    'learning_rate': 0.03,\n    'num_leaves': 31,\n    'max_depth': 10,\n    'subsample': 0.8,\n    'colsample_bytree': 0.7,\n    'n_estimators': 2000,\n    'verbose': -1,\n    'n_jobs': 4\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:40:56.334106Z","iopub.execute_input":"2025-12-20T18:40:56.334383Z","iopub.status.idle":"2025-12-20T18:40:56.346456Z","shell.execute_reply.started":"2025-12-20T18:40:56.334350Z","shell.execute_reply":"2025-12-20T18:40:56.346089Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nmodels = []\nthresholds = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    \n    pos_weight = (len(y_train) - y_train.sum()) / y_train.sum()\n    \n    clf = lgb.LGBMClassifier(**params, scale_pos_weight=pos_weight)\n    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n            callbacks=[lgb.early_stopping(100, verbose=False)])\n    \n    probs = clf.predict_proba(X_val)[:, 1]\n    best_f1 = 0\n    best_th = 0.5\n    for th in np.linspace(0.1, 0.9, 50):\n        score = f1_score(y_val, (probs > th).astype(int))\n        if score > best_f1:\n            best_f1 = score\n            best_th = th\n            \n    print(f\"Fold {fold+1} F1: {best_f1:.4f} (Threshold: {best_th:.2f})\")\n    models.append(clf)\n    thresholds.append(best_th)\n\navg_threshold = np.mean(thresholds)\nprint(f\"Average Optimal Threshold: {avg_threshold:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:40:56.347356Z","iopub.execute_input":"2025-12-20T18:40:56.347598Z","iopub.status.idle":"2025-12-20T18:41:00.313993Z","shell.execute_reply.started":"2025-12-20T18:40:56.347579Z","shell.execute_reply":"2025-12-20T18:41:00.313456Z"}},"outputs":[{"name":"stdout","text":"Fold 1 F1: 0.5143 (Threshold: 0.18)\nFold 2 F1: 0.6667 (Threshold: 0.26)\nFold 3 F1: 0.6769 (Threshold: 0.25)\nFold 4 F1: 0.5778 (Threshold: 0.66)\nFold 5 F1: 0.5484 (Threshold: 0.38)\nAverage Optimal Threshold: 0.34\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"test_log = pd.read_csv(os.path.join(DATA_PATH, 'test_log.csv'))\n\ndf_test_features = extract_features_parallel(test_log, DATA_PATH, n_jobs=4)\n\ndf_test_final = test_log.merge(df_test_features, on='object_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:41:00.314780Z","iopub.execute_input":"2025-12-20T18:41:00.315018Z","iopub.status.idle":"2025-12-20T18:54:00.630956Z","shell.execute_reply.started":"2025-12-20T18:41:00.314998Z","shell.execute_reply":"2025-12-20T18:54:00.630486Z"}},"outputs":[{"name":"stdout","text":"Loading raw lightcurves into memory...\nExtracting features for 7135 objects using 4 cores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7135 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aff527353f743698974cc8a1e34ae99"}},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"X_test = df_test_final[features]\nfor col in X_test.select_dtypes(include=['object']).columns:\n    X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:54:00.631791Z","iopub.execute_input":"2025-12-20T18:54:00.632083Z","iopub.status.idle":"2025-12-20T18:54:00.637354Z","shell.execute_reply.started":"2025-12-20T18:54:00.632054Z","shell.execute_reply":"2025-12-20T18:54:00.636873Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"test_probs = np.zeros(len(X_test))\nfor model in models:\n    test_probs += model.predict_proba(X_test)[:, 1] / len(models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:54:00.639238Z","iopub.execute_input":"2025-12-20T18:54:00.639753Z","iopub.status.idle":"2025-12-20T18:54:00.799013Z","shell.execute_reply.started":"2025-12-20T18:54:00.639716Z","shell.execute_reply":"2025-12-20T18:54:00.798638Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"predictions = (test_probs > avg_threshold).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:54:00.799565Z","iopub.execute_input":"2025-12-20T18:54:00.799740Z","iopub.status.idle":"2025-12-20T18:54:00.803667Z","shell.execute_reply.started":"2025-12-20T18:54:00.799723Z","shell.execute_reply":"2025-12-20T18:54:00.802881Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'object_id': df_test_final['object_id'],\n    'prediction': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSuccess! Saved submission.csv\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T18:54:00.804783Z","iopub.execute_input":"2025-12-20T18:54:00.805389Z","iopub.status.idle":"2025-12-20T18:54:00.831948Z","shell.execute_reply.started":"2025-12-20T18:54:00.805361Z","shell.execute_reply":"2025-12-20T18:54:00.831549Z"}},"outputs":[{"name":"stdout","text":"\nSuccess! Saved submission.csv\n                      object_id  prediction\n0      Eluwaith_Mithrim_nothrim           0\n1            Eru_heledir_archam           0\n2             Gonhir_anann_fuin           0\n3  Gwathuirim_haradrim_tegilbor           0\n4              achas_minai_maen           0\n","output_type":"stream"}],"execution_count":58}]}