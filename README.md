# ğŸŒŒ MALLORN: Tidal Disruption Event (TDE) Classifier

> **MALLORN Classifier Challenge** - Giáº£i phÃ¡p sá»­ dá»¥ng Ensemble Learning Ä‘á»ƒ phÃ¢n loáº¡i sá»± kiá»‡n thiÃªn vÄƒn TDE tá»« dá»¯ liá»‡u chuá»—i thá»i gian Ã¡nh sÃ¡ng (Lightcurves).

![Status](https://img.shields.io/badge/Status-Completed-success) ![Python](https://img.shields.io/badge/Python-3.10+-blue) ![License](https://img.shields.io/badge/License-MIT-green)

## ğŸ“‘ Má»¥c lá»¥c
1. [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)
2. [Cáº¥u trÃºc Repository](#-cáº¥u-trÃºc-repository)
3. [PhÆ°Æ¡ng phÃ¡p Ká»¹ thuáº­t](#-phÆ°Æ¡ng-phÃ¡p-ká»¹-thuáº­t)

---

## ğŸš€ Giá»›i thiá»‡u
Dá»± Ã¡n nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n phÃ¢n loáº¡i **Tidal Disruption Events (TDE)** trong dá»¯ liá»‡u thiÃªn vÄƒn mÃ´ phá»ng LSST. ThÃ¡ch thá»©c chÃ­nh bao gá»“m dá»¯ liá»‡u máº¥t cÃ¢n báº±ng (imbalanced data), chuá»—i thá»i gian khÃ´ng Ä‘á»u (irregular sampling) vÃ  nhiá»…u tá»« bá»¥i vÅ© trá»¥.

Má»¥c tiÃªu lÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh Machine Learning cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c sá»± kiá»‡n TDE (Target = 1) dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng trÃ­ch xuáº¥t tá»« Lightcurve Ä‘a bÆ°á»›c sÃ³ng (u, g, r, i, z, y).

---

## ğŸ“‚ Cáº¥u trÃºc Repository
    
* **`improved_model.ipynb`**: **Main Pipeline (Production)**.
    * **Data Loading:** Táº£i vÃ  xá»­ lÃ½ dá»¯ liá»‡u tá»« nhiá»u file rá»i ráº¡c.
    * **Advanced Feature Engineering:** TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng song song (Parallel Processing) sá»­ dá»¥ng `joblib`. Bao gá»“m: tham sá»‘ Bazin, há»‡ sá»‘ Stetson, vÃ  dá»± Ä‘oÃ¡n Gaussian Process.
    * **Hyperparameter Tuning:** Tá»± Ä‘á»™ng tá»‘i Æ°u tham sá»‘ cho LightGBM, XGBoost, CatBoost báº±ng **Optuna**.
    * **Ensemble Training:** Huáº¥n luyá»‡n mÃ´ hÃ¬nh Voting Classifier káº¿t há»£p 3 model máº¡nh nháº¥t.
    * **Submission:** Táº¡o file káº¿t quáº£ `submission_final.csv`.

---

## ğŸ›  PhÆ°Æ¡ng phÃ¡p Ká»¹ thuáº­t

Giáº£i phÃ¡p Ä‘áº¡t hiá»‡u nÄƒng cao nhá» sá»± káº¿t há»£p cá»§a cÃ¡c ká»¹ thuáº­t tiÃªn tiáº¿n:

### 1. Feature Engineering chuyÃªn sÃ¢u cho ThiÃªn vÄƒn
* **Bazin Fit:** MÃ´ hÃ¬nh hÃ³a hÃ¬nh dáº¡ng vá»¥ ná»• báº±ng hÃ m Bazin `Flux = A * (exp(-(t-t0)/tau_fall) / (1 + exp(-(t-t0)/tau_rise)))` Ä‘á»ƒ láº¥y thÃ´ng tin vá» tá»‘c Ä‘á»™ tÄƒng/giáº£m Ä‘á»™ sÃ¡ng Ä‘áº·c trÆ°ng cá»§a TDE.
* **Stetson Coefficients (J, K):** ÄÃ¡nh giÃ¡ Ä‘á»™ biáº¿n thiÃªn tin cáº­y cá»§a tÃ­n hiá»‡u, giÃºp phÃ¢n biá»‡t nhiá»…u vÃ  tÃ­n hiá»‡u thá»±c.
* **Gaussian Process Regression (GP):** Sá»­ dá»¥ng GP kernel RBF Ä‘á»ƒ ná»™i suy dá»¯ liá»‡u bá»‹ khuyáº¿t vÃ  dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c Flux táº¡i thá»i Ä‘iá»ƒm cá»±c Ä‘áº¡i (Peak), tá»« Ä‘Ã³ tÃ­nh toÃ¡n mÃ u sáº¯c (Color indices) tin cáº­y.

### 2. Ensemble Learning máº¡nh máº½
Sá»­ dá»¥ng kiáº¿n trÃºc **Voting Classifier (Soft Voting)** káº¿t há»£p 3 mÃ´ hÃ¬nh Gradient Boosting hÃ ng Ä‘áº§u:
* **LightGBM:** Tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ vÃ  hiá»‡u nÄƒng trÃªn dá»¯ liá»‡u lá»›n.
* **XGBoost:** Sá»­ dá»¥ng `tree_method='hist'` vÃ  há»— trá»£ GPU Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ huáº¥n luyá»‡n.
* **CatBoost:** Xá»­ lÃ½ tá»‘t cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n loáº¡i vÃ  dá»¯ liá»‡u nhiá»…u.

### 3. Chiáº¿n lÆ°á»£c tá»‘i Æ°u hÃ³a
* **Optuna:** Tá»± Ä‘á»™ng tÃ¬m kiáº¿m siÃªu tham sá»‘ (Hyperparameters) tá»‘i Æ°u cho tá»«ng mÃ´ hÃ¬nh thÃ nh pháº§n thay vÃ¬ chá»n thá»§ cÃ´ng.
* **Imbalance Handling:** Sá»­ dá»¥ng `scale_pos_weight` (cÄƒn chá»‰nh trá»ng sá»‘ lá»›p dá»±a trÃªn tá»· lá»‡ máº«u) vÃ  `SqrtBalanced` Ä‘á»ƒ giÃºp mÃ´ hÃ¬nh há»c tá»‘t lá»›p thiá»ƒu sá»‘ (TDE).
* **Dynamic Threshold:** Ãp dá»¥ng ngÆ°á»¡ng cáº¯t Ä‘á»™ng dá»±a trÃªn phÃ¢n vá»‹ xÃ¡c suáº¥t dá»± Ä‘oÃ¡n (percentile) thay vÃ¬ ngÆ°á»¡ng cá»©ng 0.5, giÃºp tá»‘i Ä‘a hÃ³a Recall cho cÃ¡c sá»± kiá»‡n hiáº¿m.

---
