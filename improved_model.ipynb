{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14010596,"sourceType":"datasetVersion","datasetId":8925232}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport lightgbm as lgb\nfrom scipy.optimize import curve_fit\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom joblib import Parallel, delayed\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.636217Z","iopub.execute_input":"2025-12-22T14:23:27.637171Z","iopub.status.idle":"2025-12-22T14:23:27.642267Z","shell.execute_reply.started":"2025-12-22T14:23:27.637132Z","shell.execute_reply":"2025-12-22T14:23:27.641750Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.643720Z","iopub.execute_input":"2025-12-22T14:23:27.643971Z","iopub.status.idle":"2025-12-22T14:23:27.659323Z","shell.execute_reply.started":"2025-12-22T14:23:27.643949Z","shell.execute_reply":"2025-12-22T14:23:27.658669Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import os\nimport sys\n\nclass DevNull:\n    def write(self, msg): pass\n    def flush(self): pass\n\nsys.stderr = DevNull()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.660309Z","iopub.execute_input":"2025-12-22T14:23:27.660652Z","iopub.status.idle":"2025-12-22T14:23:27.678006Z","shell.execute_reply.started":"2025-12-22T14:23:27.660628Z","shell.execute_reply":"2025-12-22T14:23:27.677392Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/mallorn-dataset' \nprint(f\"Data Path: {DATA_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.679153Z","iopub.execute_input":"2025-12-22T14:23:27.679468Z","iopub.status.idle":"2025-12-22T14:23:27.694080Z","shell.execute_reply.started":"2025-12-22T14:23:27.679444Z","shell.execute_reply":"2025-12-22T14:23:27.693382Z"}},"outputs":[{"name":"stdout","text":"Data Path: /kaggle/input/mallorn-dataset\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def bazin_func(t, A, B, t0, tau_fall, tau_rise):\n    with np.errstate(over='ignore', invalid='ignore'):\n        flux = A * (np.exp(-(t - t0) / tau_fall) / (1 + np.exp(-(t - t0) / tau_rise))) + B\n    return np.nan_to_num(flux)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.696132Z","iopub.execute_input":"2025-12-22T14:23:27.696463Z","iopub.status.idle":"2025-12-22T14:23:27.710278Z","shell.execute_reply.started":"2025-12-22T14:23:27.696415Z","shell.execute_reply":"2025-12-22T14:23:27.709631Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def fit_bazin(time, flux, flux_err):\n    if len(time) < 5: \n        return {k: np.nan for k in ['A', 'B', 't0', 'tau_fall', 'tau_rise', 'chi2']}\n\n    peak_idx = np.argmax(flux)\n    # Initial guesses\n    p0 = [flux[peak_idx], np.min(flux), time[peak_idx], 50.0, 10.0]\n    # Bounds\n    bounds = ([0, -np.inf, time.min()-50, 1e-3, 1e-3], [np.inf, np.inf, time.max()+50, 500, 500])\n\n    try:\n        popt, _ = curve_fit(bazin_func, time, flux, p0=p0, sigma=flux_err, bounds=bounds, maxfev=1000)\n        residuals = flux - bazin_func(time, *popt)\n        chi2 = np.sum((residuals / flux_err)**2) / (len(time) - 5)\n        return {'A': popt[0], 'B': popt[1], 't0': popt[2], 'tau_fall': popt[3], 'tau_rise': popt[4], 'chi2': chi2}\n    except:\n        return {k: np.nan for k in ['A', 'B', 't0', 'tau_fall', 'tau_rise', 'chi2']}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.711315Z","iopub.execute_input":"2025-12-22T14:23:27.711578Z","iopub.status.idle":"2025-12-22T14:23:27.720567Z","shell.execute_reply.started":"2025-12-22T14:23:27.711555Z","shell.execute_reply":"2025-12-22T14:23:27.720010Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def get_gp_prediction(time, flux, flux_err, t_query):\n    if len(time) < 3: return np.nan\n    kernel = C(1.0) * RBF(length_scale=20.0) + WhiteKernel(noise_level=1.0)\n    gp = GaussianProcessRegressor(kernel=kernel, alpha=flux_err**2, n_restarts_optimizer=0)\n    try:\n        gp.fit(time.reshape(-1, 1), flux)\n        pred, _ = gp.predict(np.array([[t_query]]), return_std=True)\n        return pred[0]\n    except:\n        return np.nan","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.721806Z","iopub.execute_input":"2025-12-22T14:23:27.722155Z","iopub.status.idle":"2025-12-22T14:23:27.736980Z","shell.execute_reply.started":"2025-12-22T14:23:27.722132Z","shell.execute_reply":"2025-12-22T14:23:27.736361Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def calculate_stetson(flux, flux_err):\n    n = len(flux)\n    if n < 2: return np.nan, np.nan\n    \n    mean_flux = np.mean(flux)\n    delta = (flux - mean_flux) / (flux_err + 1e-6) \n    \n    abs_delta_mean = np.mean(np.abs(delta))\n    delta_sq_mean = np.mean(delta**2)\n    k = (1 / np.sqrt(n)) * (abs_delta_mean / np.sqrt(delta_sq_mean))\n\n    j = np.sum(np.sign(delta[:-1] * delta[1:]) * np.sqrt(np.abs(delta[:-1] * delta[1:])))\n    j = (j / (n - 1)) * np.sign(j) \n    \n    return j, k","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.737987Z","iopub.execute_input":"2025-12-22T14:23:27.738196Z","iopub.status.idle":"2025-12-22T14:23:27.752142Z","shell.execute_reply.started":"2025-12-22T14:23:27.738177Z","shell.execute_reply":"2025-12-22T14:23:27.751555Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def process_single_object(obj_id, df_obj):\n    feats = {'object_id': obj_id}\n    t_min = df_obj['Time (MJD)'].min()\n    df_obj['Time_Rel'] = df_obj['Time (MJD)'] - t_min\n    \n    filters = ['u', 'g', 'r', 'i', 'z', 'y']\n    peak_time = np.nan\n    max_flux_global = -np.inf\n    \n    for f in filters:\n        df_f = df_obj[df_obj['Filter'] == f]\n        if df_f.empty:\n            for stat in ['mean', 'max', 'min', 'std', 'skew', 'stetson_j', 'stetson_k']:\n                feats[f'{f}_{stat}'] = np.nan\n            continue\n            \n        feats[f'{f}_mean'] = df_f['Flux'].mean()\n        feats[f'{f}_max'] = df_f['Flux'].max()\n        feats[f'{f}_min'] = df_f['Flux'].min()\n        feats[f'{f}_std'] = df_f['Flux'].std()\n        feats[f'{f}_skew'] = df_f['Flux'].skew()\n        \n        j, k = calculate_stetson(df_f['Flux'].values, df_f['Flux_err'].values)\n        feats[f'{f}_stetson_j'] = j\n        feats[f'{f}_stetson_k'] = k\n        \n        if f in ['g', 'r']:\n            current_max = df_f['Flux'].max()\n            if current_max > max_flux_global:\n                max_flux_global = current_max\n                peak_time = df_f.loc[df_f['Flux'].idxmax(), 'Time_Rel']\n\n        if f in ['g', 'r', 'i']:\n            bazin = fit_bazin(df_f['Time_Rel'].values, df_f['Flux'].values, df_f['Flux_err'].values)\n            for k_bazin, v_bazin in bazin.items():\n                feats[f'bazin_{f}_{k_bazin}'] = v_bazin\n\n    if not np.isnan(peak_time):\n        flux_at_peak = {}\n        for f in filters:\n            df_f = df_obj[df_obj['Filter'] == f]\n            flux_at_peak[f] = get_gp_prediction(\n                df_f['Time_Rel'].values, df_f['Flux'].values, df_f['Flux_err'].values, peak_time\n            )\n        pairs = [('u','g'), ('g','r'), ('r','i'), ('i','z')]\n        for f1, f2 in pairs:\n            val1, val2 = flux_at_peak.get(f1, np.nan), flux_at_peak.get(f2, np.nan)\n            feats[f'gp_color_{f1}_{f2}'] = val1 - val2 if (not np.isnan(val1) and not np.isnan(val2)) else np.nan\n            \n    return feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.753344Z","iopub.execute_input":"2025-12-22T14:23:27.753818Z","iopub.status.idle":"2025-12-22T14:23:27.772394Z","shell.execute_reply.started":"2025-12-22T14:23:27.753783Z","shell.execute_reply":"2025-12-22T14:23:27.771759Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def extract_features_parallel(log_df, data_path, n_jobs=-1):\n    print(\"Loading raw lightcurves into memory...\")\n    all_chunks = []\n    unique_splits = log_df['split'].unique()\n    \n    for split in unique_splits:\n        is_train = 'target' in log_df.columns\n        filename = 'train_full_lightcurves.csv' if is_train else 'test_full_lightcurves.csv'\n        \n        path = os.path.join(data_path, split, filename)\n        if os.path.exists(path):\n            df_chunk = pd.read_csv(path)\n            valid_ids = set(log_df[log_df['split'] == split]['object_id'])\n            df_chunk = df_chunk[df_chunk['object_id'].isin(valid_ids)]\n            all_chunks.append(df_chunk)\n            \n    if not all_chunks:\n        print(\"Error: No lightcurves found!\")\n        return pd.DataFrame()\n\n    full_lc = pd.concat(all_chunks)\n    \n    grouped = full_lc.groupby('object_id')\n    object_ids = list(grouped.groups.keys())\n    \n    print(f\"Extracting features for {len(object_ids)} objects using {n_jobs} cores...\")\n    \n    results = Parallel(n_jobs=n_jobs, backend='loky')(\n        delayed(process_single_object)(obj_id, grouped.get_group(obj_id))\n        for obj_id in tqdm(object_ids)\n    )\n    \n    return pd.DataFrame(results)\n\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.773591Z","iopub.execute_input":"2025-12-22T14:23:27.774048Z","iopub.status.idle":"2025-12-22T14:23:27.793873Z","shell.execute_reply.started":"2025-12-22T14:23:27.774014Z","shell.execute_reply":"2025-12-22T14:23:27.792899Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(\"--- PROCESSING TRAIN DATA ---\")\ntrain_log = pd.read_csv(os.path.join(DATA_PATH, 'train_log.csv'))\n\ndf_train_features = extract_features_parallel(train_log, DATA_PATH, n_jobs=4)\n\ndf_train_final = train_log.merge(df_train_features, on='object_id', how='left')\nprint(f\"Train Data Shape: {df_train_final.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:23:27.800657Z","iopub.execute_input":"2025-12-22T14:23:27.801045Z","iopub.status.idle":"2025-12-22T14:29:56.163601Z","shell.execute_reply.started":"2025-12-22T14:23:27.801003Z","shell.execute_reply":"2025-12-22T14:29:56.162865Z"}},"outputs":[{"name":"stdout","text":"--- PROCESSING TRAIN DATA ---\nLoading raw lightcurves into memory...\nExtracting features for 3043 objects using 4 cores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3043 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6df09d4c64a14ec08e578cc80bfbeaf0"}},"metadata":{}},{"name":"stdout","text":"Train Data Shape: (3043, 72)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:56.165586Z","iopub.execute_input":"2025-12-22T14:29:56.165899Z","iopub.status.idle":"2025-12-22T14:29:56.993500Z","shell.execute_reply.started":"2025-12-22T14:29:56.165875Z","shell.execute_reply":"2025-12-22T14:29:56.992804Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"ignore_cols = ['object_id', 'target', 'split', 'English Translation', 'SpecType']\nfeatures = [c for c in df_train_final.columns if c not in ignore_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:56.994538Z","iopub.execute_input":"2025-12-22T14:29:56.995165Z","iopub.status.idle":"2025-12-22T14:29:56.999348Z","shell.execute_reply.started":"2025-12-22T14:29:56.995137Z","shell.execute_reply":"2025-12-22T14:29:56.998524Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"X = df_train_final[features].copy()\n\nX = X.replace([np.inf, -np.inf], np.nan)\n\nX = X.fillna(0)\ny = df_train_final['target']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:57.000651Z","iopub.execute_input":"2025-12-22T14:29:57.000944Z","iopub.status.idle":"2025-12-22T14:29:57.022836Z","shell.execute_reply.started":"2025-12-22T14:29:57.000921Z","shell.execute_reply":"2025-12-22T14:29:57.022224Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"for col in X.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:57.025277Z","iopub.execute_input":"2025-12-22T14:29:57.025603Z","iopub.status.idle":"2025-12-22T14:29:57.029787Z","shell.execute_reply.started":"2025-12-22T14:29:57.025581Z","shell.execute_reply":"2025-12-22T14:29:57.029201Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof_preds = np.zeros(len(X))\nmodels_ensemble = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:57.030820Z","iopub.execute_input":"2025-12-22T14:29:57.031397Z","iopub.status.idle":"2025-12-22T14:29:57.044786Z","shell.execute_reply.started":"2025-12-22T14:29:57.031369Z","shell.execute_reply":"2025-12-22T14:29:57.044109Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from catboost import CatBoostClassifier ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:29:57.045872Z","iopub.execute_input":"2025-12-22T14:29:57.046684Z","iopub.status.idle":"2025-12-22T14:29:57.317989Z","shell.execute_reply.started":"2025-12-22T14:29:57.046651Z","shell.execute_reply":"2025-12-22T14:29:57.317523Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"test_log = pd.read_csv(os.path.join(DATA_PATH, 'test_log.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:31:15.981188Z","iopub.execute_input":"2025-12-22T14:31:15.981544Z","iopub.status.idle":"2025-12-22T14:31:16.046458Z","shell.execute_reply.started":"2025-12-22T14:31:15.981518Z","shell.execute_reply":"2025-12-22T14:31:16.045918Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df_test_features = extract_features_parallel(test_log, DATA_PATH, n_jobs=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:31:16.047459Z","iopub.execute_input":"2025-12-22T14:31:16.047744Z","iopub.status.idle":"2025-12-22T14:46:21.381044Z","shell.execute_reply.started":"2025-12-22T14:31:16.047721Z","shell.execute_reply":"2025-12-22T14:46:21.380404Z"}},"outputs":[{"name":"stdout","text":"Loading raw lightcurves into memory...\nExtracting features for 7135 objects using 4 cores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7135 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e14076d2844c8c85fa5a2d60ebf580"}},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"df_test_final = test_log.merge(df_test_features, on='object_id', how='left')\nprint(f\"Test Data Shape: {df_test_final.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:46:21.382512Z","iopub.execute_input":"2025-12-22T14:46:21.382784Z","iopub.status.idle":"2025-12-22T14:46:21.397892Z","shell.execute_reply.started":"2025-12-22T14:46:21.382761Z","shell.execute_reply":"2025-12-22T14:46:21.397259Z"}},"outputs":[{"name":"stdout","text":"Test Data Shape: (7135, 71)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n    \n    print(f\"Fold {fold+1}: Running SMOTE...\")\n    try:\n        smote = SMOTE(sampling_strategy=0.2, random_state=42)\n        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n    except ValueError:\n        print(\"SMOTE failed, using raw data.\")\n        X_train_res, y_train_res = X_train, y_train\n\n    clf_lgb = lgb.LGBMClassifier(\n        objective='binary', boosting_type='gbdt',\n        verbose=-1, random_state=42, n_jobs=-1,\n        learning_rate=0.00820959390156126,\n        n_estimators=1456,\n        num_leaves=21,\n        max_depth=7,\n        min_child_samples=18,\n        subsample=0.8056429645734329,\n        colsample_bytree=0.7037094223073973,\n        reg_alpha=1.2090883197470177,\n        reg_lambda=3.5948946953880816e-08\n    )\n    \n    clf_xgb = XGBClassifier(\n        objective='binary:logistic', eval_metric='logloss',\n        random_state=42, use_label_encoder=False,\n        tree_method='hist',\n        device='cuda' if USE_GPU else 'cpu',\n        learning_rate=0.0205217807496452,\n        n_estimators=1185,\n        max_depth=7,\n        min_child_weight=7,\n        subsample=0.7753093208264389,\n        colsample_bytree=0.8265862295956217,\n        gamma=1.0058203352400668,\n        reg_alpha=4.053334043323454e-06,\n        reg_lambda=0.09447983849476049\n    )\n    \n    clf_cat = CatBoostClassifier(\n        loss_function='Logloss', eval_metric='F1',\n        verbose=0, random_seed=42, allow_writing_files=False,\n        task_type='CPU'\n        learning_rate=0.04297575732378107,\n        iterations=735,\n        depth=7,\n        l2_leaf_reg=5.44676657488797,\n        border_count=182,\n        random_strength=2.5066619218798087,\n        bagging_temperature=0.9978326033997912\n    )\n    \n    eclf = VotingClassifier(\n        estimators=[('lgb', clf_lgb), ('xgb', clf_xgb), ('cat', clf_cat)],\n        voting='soft',\n        weights=[1, 1, 1] \n    )\n    \n    eclf.fit(X_train_res, y_train_res)\n    \n    val_probs = eclf.predict_proba(X_val)[:, 1]\n    oof_preds[val_idx] = val_probs\n    \n    best_f1, best_th = 0, 0.5\n    for th in np.linspace(0.1, 0.9, 100):\n        score = f1_score(y_val, (val_probs > th).astype(int))\n        if score > best_f1: best_f1, best_th = score, th\n            \n    print(f\"Fold {fold+1} Trifecta F1: {best_f1:.4f} (Th: {best_th:.2f})\")\n    models_ensemble.append(eclf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T16:29:16.089461Z","iopub.execute_input":"2025-12-22T16:29:16.090482Z","iopub.status.idle":"2025-12-22T16:30:34.209074Z","shell.execute_reply.started":"2025-12-22T16:29:16.090417Z","shell.execute_reply":"2025-12-22T16:30:34.208243Z"}},"outputs":[{"name":"stdout","text":"Fold 1: Running SMOTE...\nSMOTE failed, using raw data.\nFold 1 Trifecta F1: 0.4746 (Th: 0.10)\nFold 2: Running SMOTE...\nSMOTE failed, using raw data.\nFold 2 Trifecta F1: 0.6400 (Th: 0.23)\nFold 3: Running SMOTE...\nSMOTE failed, using raw data.\nFold 3 Trifecta F1: 0.6349 (Th: 0.10)\nFold 4: Running SMOTE...\nSMOTE failed, using raw data.\nFold 4 Trifecta F1: 0.6349 (Th: 0.15)\nFold 5: Running SMOTE...\nSMOTE failed, using raw data.\nFold 5 Trifecta F1: 0.4571 (Th: 0.11)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"thresholds = np.linspace(0.01, 0.99, 200)\nf1_list = [f1_score(y, (oof_preds > t).astype(int)) for t in thresholds]\nglobal_best_thresh = thresholds[np.argmax(f1_list)]\nprint(f\"\\nGlobal Best F1: {np.max(f1_list):.4f} at Threshold: {global_best_thresh:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T16:30:43.092316Z","iopub.execute_input":"2025-12-22T16:30:43.093021Z","iopub.status.idle":"2025-12-22T16:30:43.572875Z","shell.execute_reply.started":"2025-12-22T16:30:43.092985Z","shell.execute_reply":"2025-12-22T16:30:43.572063Z"}},"outputs":[{"name":"stdout","text":"\nGlobal Best F1: 0.5559 at Threshold: 0.09\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import optuna\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\n\nignore_cols = ['object_id', 'target', 'split', 'English Translation', 'SpecType']\nfeatures = [c for c in df_train_final.columns if c not in ignore_cols]\n\nX = df_train_final[features].copy().replace([np.inf, -np.inf], np.nan)\ny = df_train_final['target']\n\nfor col in X.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    X[col] = le.fit_transform(X[col].astype(str))\n\nneg = (y==0).sum()\npos = (y==1).sum()\nscale_pos_weight = neg / pos\n\ndef objective(trial):\n    param = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'verbosity': -1,\n        'boosting_type': 'gbdt',\n        'n_jobs': -1,\n        'random_state': 42,\n        'scale_pos_weight': scale_pos_weight,\n        \n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 400, 1500),\n        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n        'max_depth': trial.suggest_int('max_depth', 5, 15),\n        'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.95),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.95),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n    \n    for train_idx, val_idx in skf.split(X, y):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model = lgb.LGBMClassifier(**param)\n        model.fit(X_train, y_train)\n        \n        # Tìm ngưỡng tối ưu nội bộ cho fold này\n        preds_proba = model.predict_proba(X_val)[:, 1]\n        best_f1 = 0\n        for th in np.linspace(0.1, 0.9, 20):\n            score = f1_score(y_val, (preds_proba > th).astype(int))\n            if score > best_f1: best_f1 = score\n        \n        f1_scores.append(best_f1)\n        \n    return np.mean(f1_scores)\n\nprint(\"Starting Optuna Tuning for LightGBM...\")\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\n\nprint(f\"Best F1: {study.best_value:.4f}\")\nprint(\"Best Params:\")\nfor key, value in study.best_params.items():\n    print(f\"    '{key}': {value},\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T14:47:00.304684Z","iopub.execute_input":"2025-12-22T14:47:00.305042Z","iopub.status.idle":"2025-12-22T15:03:12.417727Z","shell.execute_reply.started":"2025-12-22T14:47:00.305010Z","shell.execute_reply":"2025-12-22T15:03:12.417063Z"}},"outputs":[{"name":"stdout","text":"Starting Optuna Tuning for LightGBM...\nBest F1: 0.6218\nBest Params:\n    'learning_rate': 0.00820959390156126,\n    'n_estimators': 1456,\n    'num_leaves': 21,\n    'max_depth': 7,\n    'min_child_samples': 18,\n    'subsample': 0.8056429645734329,\n    'colsample_bytree': 0.7037094223073973,\n    'reg_alpha': 1.2090883197470177,\n    'reg_lambda': 3.5948946953880816e-08,\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import optuna\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport numpy as np\nimport torch\n\nif 'scale_pos_weight' not in globals():\n    neg = (y==0).sum()\n    pos = (y==1).sum()\n    scale_pos_weight = neg / pos\n\nUSE_GPU = torch.cuda.is_available()\n\ndef objective_xgb(trial):\n    param = {\n        'objective': 'binary:logistic',\n        'eval_metric': 'logloss',\n        \n        'tree_method': 'hist',   \n        'device': 'cuda' if USE_GPU else 'cpu',\n        \n        'random_state': 42,\n        'use_label_encoder': False,\n        'scale_pos_weight': scale_pos_weight,\n        \n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n        'n_estimators': trial.suggest_int('n_estimators', 500, 1500),\n        'max_depth': trial.suggest_int('max_depth', 4, 12),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n        'subsample': trial.suggest_float('subsample', 0.5, 0.95),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.95),\n        'gamma': trial.suggest_float('gamma', 0, 5),\n        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n    \n    for train_idx, val_idx in skf.split(X, y):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model = XGBClassifier(**param)\n        model.fit(X_train, y_train)\n        \n        preds_proba = model.predict_proba(X_val)[:, 1]\n        best_f1 = 0\n        for th in np.linspace(0.1, 0.9, 20):\n            score = f1_score(y_val, (preds_proba > th).astype(int))\n            if score > best_f1: best_f1 = score\n        f1_scores.append(best_f1)\n        \n    return np.mean(f1_scores)\n\nprint(\"Starting Optuna for XGBoost...\")\nstudy_xgb = optuna.create_study(direction='maximize')\nstudy_xgb.optimize(objective_xgb, n_trials=30)\nprint(\"Best XGB Params:\", study_xgb.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T15:23:30.095448Z","iopub.execute_input":"2025-12-22T15:23:30.095838Z","iopub.status.idle":"2025-12-22T15:32:52.583144Z","shell.execute_reply.started":"2025-12-22T15:23:30.095810Z","shell.execute_reply":"2025-12-22T15:32:52.582279Z"}},"outputs":[{"name":"stdout","text":"Starting Optuna for XGBoost...\nBest XGB Params: {'learning_rate': 0.0205217807496452, 'n_estimators': 1185, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7753093208264389, 'colsample_bytree': 0.8265862295956217, 'gamma': 1.0058203352400668, 'reg_alpha': 4.053334043323454e-06, 'reg_lambda': 0.09447983849476049}\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import optuna\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport numpy as np\n\ndef objective_cat(trial):\n    param = {\n        'loss_function': 'Logloss',\n        'eval_metric': 'F1',\n        'task_type': 'CPU',  \n        'verbose': 0,\n        'random_seed': 42,\n        'allow_writing_files': False,\n        'auto_class_weights': 'Balanced',\n        \n        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n        'iterations': trial.suggest_int('iterations', 500, 1500),\n        'depth': trial.suggest_int('depth', 4, 10),\n        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n        'border_count': trial.suggest_int('border_count', 32, 255),\n        'random_strength': trial.suggest_float('random_strength', 0, 10),\n        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1)\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n    \n    for train_idx, val_idx in skf.split(X, y):\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n        \n        model = CatBoostClassifier(**param)\n        model.fit(X_train, y_train)\n        \n        preds_proba = model.predict_proba(X_val)[:, 1]\n        best_f1 = 0\n        for th in np.linspace(0.1, 0.9, 20):\n            score = f1_score(y_val, (preds_proba > th).astype(int))\n            if score > best_f1: best_f1 = score\n        f1_scores.append(best_f1)\n        \n    return np.mean(f1_scores)\n\nprint(\"Starting Optuna for CatBoost (CPU Mode)...\")\nstudy_cat = optuna.create_study(direction='maximize')\nstudy_cat.optimize(objective_cat, n_trials=30)\nprint(\"Best CatBoost Params:\", study_cat.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T15:43:02.669042Z","iopub.execute_input":"2025-12-22T15:43:02.669918Z","iopub.status.idle":"2025-12-22T16:23:11.293062Z","shell.execute_reply.started":"2025-12-22T15:43:02.669887Z","shell.execute_reply":"2025-12-22T16:23:11.292494Z"}},"outputs":[{"name":"stdout","text":"Starting Optuna for CatBoost (CPU Mode)...\nBest CatBoost Params: {'learning_rate': 0.04297575732378107, 'iterations': 735, 'depth': 7, 'l2_leaf_reg': 5.44676657488797, 'border_count': 182, 'random_strength': 2.5066619218798087, 'bagging_temperature': 0.9978326033997912}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"X_test = df_test_final[features].copy()\nX_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n\nfor col in X_test.select_dtypes(include=['object']).columns:\n    X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0)\n\ntest_probs = np.zeros(len(X_test))\nfor model in models_ensemble:\n    test_probs += model.predict_proba(X_test)[:, 1] / len(models_ensemble)\n\npredictions = (test_probs > global_best_thresh).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T16:30:49.947176Z","iopub.execute_input":"2025-12-22T16:30:49.948106Z","iopub.status.idle":"2025-12-22T16:30:54.329836Z","shell.execute_reply.started":"2025-12-22T16:30:49.948068Z","shell.execute_reply":"2025-12-22T16:30:54.329273Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'object_id': df_test_final['object_id'],\n    'prediction': predictions\n})\n\nsubmission.to_csv('submission_2.csv', index=False)\nprint(\"\\nSuccess! Saved submission.csv with SMOTE & Ensemble.\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T16:30:54.330874Z","iopub.execute_input":"2025-12-22T16:30:54.331113Z","iopub.status.idle":"2025-12-22T16:30:54.350168Z","shell.execute_reply.started":"2025-12-22T16:30:54.331089Z","shell.execute_reply":"2025-12-22T16:30:54.349506Z"}},"outputs":[{"name":"stdout","text":"\nSuccess! Saved submission.csv with SMOTE & Ensemble.\n                      object_id  prediction\n0      Eluwaith_Mithrim_nothrim           0\n1            Eru_heledir_archam           0\n2             Gonhir_anann_fuin           0\n3  Gwathuirim_haradrim_tegilbor           0\n4              achas_minai_maen           0\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"for col in X.select_dtypes(include=['object']).columns:\n    le = LabelEncoder()\n    full_col = pd.concat([X[col].astype(str), X_test[col].astype(str)])\n    le.fit(full_col)\n    X[col] = le.transform(X[col].astype(str))\n    X_test[col] = le.transform(X_test[col].astype(str))\n\nneg = (y==0).sum()\npos = (y==1).sum()\nsqrt_weight = np.sqrt(neg / pos) \nprint(f\"Original Weight Ratio: {neg/pos:.2f} -> Adjusted (Sqrt): {sqrt_weight:.2f}\")\n\nUSE_GPU = torch.cuda.is_available()\n\nclf_lgb = lgb.LGBMClassifier(\n    objective='binary', boosting_type='dart',\n    learning_rate=0.05, n_estimators=1000,\n    num_leaves=31, max_depth=-1,\n    scale_pos_weight=sqrt_weight, \n    colsample_bytree=0.7, subsample=0.7,\n    n_jobs=-1, random_state=42, verbose=-1\n)\n\nclf_xgb = XGBClassifier(\n    objective='binary:logistic', eval_metric='logloss',\n    learning_rate=0.03, n_estimators=1000, max_depth=6,\n    scale_pos_weight=sqrt_weight,\n    colsample_bytree=0.7, subsample=0.7,\n    tree_method='hist', device='cuda' if USE_GPU else 'cpu',\n    use_label_encoder=False, random_state=42\n)\n\nclf_cat = CatBoostClassifier(\n    loss_function='Logloss', eval_metric='F1',\n    learning_rate=0.03, iterations=1000, depth=6,\n    auto_class_weights='SqrtBalanced',\n    task_type='CPU',\n    verbose=0, random_seed=42, allow_writing_files=False\n)\n\neclf = VotingClassifier(\n    estimators=[('lgb', clf_lgb), ('xgb', clf_xgb), ('cat', clf_cat)],\n    voting='soft', weights=[1, 1, 1]\n)\n\nprint(\"Training on Full Dataset...\")\neclf.fit(X, y)\n\nprint(\"Predicting Test Data...\")\ntest_probs = eclf.predict_proba(X_test)[:, 1]\n\ntrain_tde_rate = y.mean()\nprint(f\"TDE Rate in Train: {train_tde_rate:.2%}\")\n\ntarget_percentile = 100 * (1 - train_tde_rate * 1.1) \ndynamic_threshold = np.percentile(test_probs, target_percentile)\n\nprint(f\"Dynamic Threshold (Top {train_tde_rate*1.1:.1%} predictions): {dynamic_threshold:.4f}\")\n\npredictions = (test_probs > dynamic_threshold).astype(int)\n\nn_tde_pred = predictions.sum()\nprint(f\"Predicted {n_tde_pred} TDEs out of {len(predictions)} objects ({n_tde_pred/len(predictions):.2%})\")\n\nsubmission = pd.DataFrame({\n    'object_id': df_test_final['object_id'],\n    'prediction': predictions\n})\n\nsubmission.to_csv('submission_final.csv', index=False)\nprint(\"\\nSuccess! Saved submission_final.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T17:20:58.987186Z","iopub.execute_input":"2025-12-22T17:20:58.987948Z","iopub.status.idle":"2025-12-22T17:21:22.343363Z","shell.execute_reply.started":"2025-12-22T17:20:58.987915Z","shell.execute_reply":"2025-12-22T17:21:22.342559Z"}},"outputs":[{"name":"stdout","text":"Original Weight Ratio: 19.56 -> Adjusted (Sqrt): 4.42\nTraining on Full Dataset...\nPredicting Test Data...\nTDE Rate in Train: 4.86%\nDynamic Threshold (Top 5.3% predictions): 0.1195\nPredicted 382 TDEs out of 7135 objects (5.35%)\n\nSuccess! Saved submission_final.csv\n","output_type":"stream"}],"execution_count":51}]}
